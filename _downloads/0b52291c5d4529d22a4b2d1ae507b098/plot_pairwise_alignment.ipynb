{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pairwise functional alignment\n===================================================================\n\nIn this tutorial, we show how to better predict new contrasts for a target\nsubject using source subject corresponding contrasts and data in common.\n\nWe mostly rely on python common packages and on nilearn to handle functional\ndata in a clean fashion.\n\n\nTo run this example, you must launch IPython via ``ipython\n--matplotlib`` in a terminal, or use ``jupyter-notebook``.\n    :depth: 1\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve the data\n-----------------\nIn this example we use the IBC dataset, which include a large number of\ndifferent contrasts maps for 12 subjects. We download the images for\nsubjects sub-01 and sub-02 (or retrieve them if they were already downloaded)\nFiles is the list of paths for each subjects.\ndf is a dataframe with metadata about each of them.\nmask is an appropriate nifti image to select the data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign.fetch_example_data import fetch_ibc_subjects_contrasts\nfiles, df, mask = fetch_ibc_subjects_contrasts(\n    ['sub-01', 'sub-02'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a masker\n---------------\nWe define a nilearn masker that will be used to handle relevant data.\n  For more information, visit :\n  'http://nilearn.github.io/manipulating_images/masker_objects.html'\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.input_data import NiftiMasker\nmasker = NiftiMasker(mask_img=mask)\nmask\nmasker.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the data\n ----------------\n\u00a0For each subject, for each task and conditions, our dataset contains two\n independent acquisitions, similar except for one acquisition parameter, the\n encoding phase used that was either Antero-Posterior (AP) or Postero-Anterior (PA).\n\n Although this induces small differences in the final data, we will take\n\u00a0advantage of these \"duplicates to create a training and a testing set that\n contains roughly the same signals but acquired totally independently.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The training fold, used to learn alignment from source subject toward target:\n# * source train: AP contrasts for subject sub-01\n# * target train: AP contrasts for subject sub-02\n\nsource_train = df[df.subject == 'sub-01'][df.acquisition == 'ap'].path.values\ntarget_train = df[df.subject == 'sub-02'][df.acquisition == 'ap'].path.values\n\n# The testing fold:\n#\u00a0* source test: PA contrasts for subject sub-01, used to predict\n#   the corresponding contrasts of subject sub-02\n# * target test: PA contrasts for subject sub-02, used as a ground truth\n#   to score our predictions\n\nsource_test = df[df.subject == 'sub-01'][df.acquisition == 'pa'].path.values\ntarget_test = df[df.subject == 'sub-02'][df.acquisition == 'pa'].path.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the estimator, fit it and predict\n----------------------------------------\nTo proceed with alignment we use PairwiseAlignment class. We will use the\ncommon model proposed in the literature:\n* we will align the whole brain through multiple local alignments.\n* these alignments are calculated on a parcellation of the brain in 150\n  pieces, this parcellation creates group of functionnally similar voxels.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign.pairwise_alignment import PairwiseAlignment\nalignement_estimator = PairwiseAlignment(\n    alignment_method='scaled_orthogonal', n_pieces=150, mask=masker)\n# Learn alignment operator from subject 1 to subject 2 on training data\nalignement_estimator.fit(source_train, target_train)\n# Predict test data for subject 2 from subject 1\ntarget_pred = alignement_estimator.transform(source_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Score the baseline and the prediction\n -------------------------------------\n\u00a0We use a utility scoring function to measure the voxelwise correlation between\n the prediction and the ground truth. That is, for each voxel, we measure the\n correlation between its profile of activation without and with alignment,\n to see if alignment was able to predict a signal more alike the ground truth.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fmralign._utils import voxelwise_correlation\n\n# Now we use this scoring function to compare the correlation of aligned and\n# original data from sub-01 made with the real PA contrasts of sub-02.\n\nbaseline_score = voxelwise_correlation(\n    target_test, source_test, masker)\naligned_score = voxelwise_correlation(\n    target_test, target_pred, masker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the measures\n ---------------------\n Finally we plot both scores\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\nbaseline_display = plotting.plot_stat_map(\n    baseline_score, display_mode=\"z\", vmax=1, cut_coords=[-15, -5])\nbaseline_display.title(\"Baseline correlation wt ground truth\")\ndisplay = plotting.plot_stat_map(\n    aligned_score, display_mode=\"z\", cut_coords=[-15, -5], vmax=1)\ndisplay.title(\"Prediction correlation wt ground truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see on the plot that after alignment the prediction made for one\nsubject data, informed by another subject are greatly improved.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}